% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.


@ARTICLE{Veerabadran2023-cn,
  abbr = {VSS 2023},
  title     = "Cortically motivated recurrence enables visual task
               extrapolation",
  author    = "Veerabadran, Vijay and Tang, Yuan and Raina, Ritik and de Sa,
               Virginia",
  journal   = "J. Vis.",
  abstract  = "Feedforward deep neural networks have become the standard class of models in computer vision. Yet, they possess a striking difference relative to their biological counterparts which predominantly perform...",
  publisher = "The Association for Research in Vision and Ophthalmology",
  selected  = {true},
  volume    =  23,
  number    =  9,
  pages     = "4684--4684",
  month     =  aug,
  html      =  {https://jov.arvojournals.org/article.aspx?articleid=2791810},
  pdf       =  {https://jov.arvojournals.org/article.aspx?articleid=2791810},
  year      =  2023,
}

@ARTICLE{Veerabadran2020-xl,
abbr = {arXiv},
  title         = "Learning compact generalizable neural representations
                   supporting perceptual grouping",
  author        = "Veerabadran, Vijay and De Sa, Virginia R",
  abstract      = "Work at the intersection of vision science and deep learning
                   is starting to explore the efficacy of deep convolutional
                   networks (DCNs) and recurrent networks in solving perceptual
                   grouping problems that underlie primate visual recognition
                   and segmentation. Here, we extend this line of work to
                   investigate the compactness and generalizability of DCN
                   solutions to learning low-level perceptual grouping routines
                   involving contour integration. We introduce V1Net, a
                   bio-inspired recurrent unit that incorporates lateral
                   connections ubiquitous in cortical circuitry. Feedforward
                   convolutional layers in DCNs can be substituted with V1Net
                   modules to enhance their contextual visual processing
                   support for perceptual grouping. We compare the learning
                   efficiency and accuracy of V1Net-DCNs to that of 14
                   carefully selected feedforward and recurrent neural
                   architectures (including state-of-the-art DCNs) on
                   MarkedLong -- a synthetic forced-choice contour integration
                   dataset of 800,000 images we introduce here -- and the
                   previously published Pathfinder contour integration
                   benchmarks. We gauged solution generalizability by measuring
                   the transfer learning performance of our candidate models
                   trained on MarkedLong that were fine-tuned to learn
                   PathFinder. Our results demonstrate that a compact 3-layer
                   V1Net-DCN matches or outperforms the test accuracy and
                   sample efficiency of all tested comparison models which
                   contain between 5x and 1000x more trainable parameters; we
                   also note that V1Net-DCN learns the most compact
                   generalizable solution to MarkedLong. A visualization of the
                   temporal dynamics of a V1Net-DCN elucidates its usage of
                   interpretable grouping computations to solve MarkedLong. The
                   compact and rich representations of V1Net-DCN also make it a
                   promising candidate to build on-device machine vision
                   algorithms as well as help better understand biological
                   cortical circuitry.",
  month         =  jun,
  year          =  2020,
  journal = {arXiv preprint},
  keywords      = "Vijay's pubs",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  html     = {https://arxiv.org/abs/2006.11716},
  pdf      = {https://arxiv.org/pdf/2006.11716.pdf},
  eprint        = "2006.11716"
}

@ARTICLE{Veerabadran2022-dz,
  abbr    = {VSS 2023},
  title    = "Cortically motivated recurrence enables task extrapolation",
  author   = "Veerabadran, Vijay and Tang, Yuan and Raina, Ritik and De Sa,
              Virginia R",
  abstract = "Feedforward deep neural networks have become the standard class
              of models in the field of computer vision. Yet, they possess a
              striking difference relative to their biological counterparts
              which predominantly perform ``recurrent'' computations. Why do
              biological neurons evolve to employ recurrence pervasively? In
              this paper, we show that a recurrent network is able to flexibly
              adapt its computational budget during inference and generalize
              within-task across difficulties. Simultaneously in this study, we
              contribute a recurrent module we call LocRNN that is designed
              based on a prior computational model of local recurrent
              intracortical connections in primates to support such dynamic
              task extrapolation. LocRNN learns highly accurate solutions to
              the challenging visual reasoning problems of Mazes and PathFinder
              that we use here. More importantly, it is able to flexibly use
              less or more recurrent iterations during inference to zero-shot
              generalize to less- and more difficult instantiations of each
              task without requiring extra training data, a potential
              functional advantage of recurrence that biological visual systems
              capitalize on. Feedforward networks on the other hand with their
              fixed computational graphs only partially exhibit this trend,
              potentially owing to image-level similarities across
              difficulties. We also posit an intriguing tradeoff between
              recurrent networks' representational capacity and their stability
              in the recurrent state space. Our work encourages further study
              of the role of recurrence in deep learning models -- especially
              from the context of out-of-distribution generalization \& task
              extrapolation -- and their properties of task performance and
              stability.",
  journal  =  {Vision Sciences Society, COSYNE},
  month    =  may,
  html     =  {https://openreview.net/forum?id=3mji6eUxzY},
  pdf      =  {https://openreview.net/pdf?id=3mji6eUxzY},
  year     =  2023,
  keywords = "Vijay's pubs"
}

@ARTICLE{Veerabadran2022-eg,
  abbr = {VSS 2022},
  title     = "Bio-inspired divisive normalization improves object recognition
               performance in {ANNs}",
  author    = "Veerabadran, Vijay and Raina, Ritik and De Sa, Virginia",
  journal   = "Vision Sciences Society",
  publisher = "Association for Research in Vision and Ophthalmology (ARVO)",
  volume    =  22,
  number    =  14,
  pages     = "3592",
  month     =  dec,
  year      =  2022,
  html = {https://jov.arvojournals.org/article.aspx?articleid=2784293},
  abstract = "In this work we introduce DivNormEI, a novel bio-inspired convolutional network that performs divisive normalization, a canonical cortical computation, along with lateral inhibition and excitation that is tailored for integration into modern Artificial Neural Networks (ANNs). DivNormEI, an extension of prior computational models of divisive normalization (Schwartz & Simoncelli, 2001; Robinson et. al, 2007) in the primate primary visual cortex, is implemented as a modular fully differentiable neural network layer that can be integrated in a straightforward manner into most commonly used modern ANNs. DivNormEI normalizes incoming activations via learned non-linear within-feature shunting inhibition along with across-feature linear lateral inhibition and excitation. In this work, we show how the integration of DivNormEI within a task-driven self-supervised encoder-decoder architecture encourages the emergence of the well-known contrast-invariant tuning property found to be exhibited by simple cells in the primate primary visual cortex. In addition, the integration of DivNormEI into an ANN (VGG-9 network) trained to perform large-scale object recognition on static images from the ImageNet-100 dataset improves both sample efficiency and top-1 accuracy on a held-out validation set. We also discuss the ability of a larger hybrid ANN (ResNet-50 with hierarchical placement of DivNormEI) to perform competitively on the more challenging task of semantic image segmentation. We believe our findings from the bio-inspired DivNormEI model that simultaneously explains properties found in primate V1 neurons and outperforms the competing baseline architecture on large-scale object recognition will promote further investigation of this crucial cortical computation in the context of modern machine learning tasks and ANNs.",
  pdf = {},
  keywords  = "Vijay's pubs",
  language  = "en"
}

@ARTICLE{Veerabadran2023-ab,
  abbr={Nature 2023},
  title    = "Subtle adversarial image manipulations influence both human and
              machine perception",
  author   = "Veerabadran, Vijay and Goldman, Josh and Shankar, Shreya and
              Cheung, Brian and Papernot, Nicolas and Kurakin, Alexey and
              Goodfellow, Ian and Shlens, Jonathon and Sohl-Dickstein, Jascha
              and Mozer, Michael C and Elsayed, Gamaleldin F",
  abstract = "Although artificial neural networks (ANNs) were inspired by the
              brain, ANNs exhibit a brittleness not generally observed in human
              perception. One shortcoming of ANNs is their susceptibility to
              adversarial perturbations-subtle modulations of natural images
              that result in changes to classification decisions, such as
              confidently mislabelling an image of an elephant, initially
              classified correctly, as a clock. In contrast, a human observer
              might well dismiss the perturbations as an innocuous imaging
              artifact. This phenomenon may point to a fundamental difference
              between human and machine perception, but it drives one to ask
              whether human sensitivity to adversarial perturbations might be
              revealed with appropriate behavioral measures. Here, we find that
              adversarial perturbations that fool ANNs similarly bias human
              choice. We further show that the effect is more likely driven by
              higher-order statistics of natural images to which both humans
              and ANNs are sensitive, rather than by the detailed architecture
              of the ANN.",
  journal  = "Nature Communications",
  volume   =  14,
  number   =  1,
  pages    = "4933",
  month    =  aug,
  year     =  2023,
  keywords = "Vijay's pubs",
  html     = {https://www.nature.com/articles/s41467-023-40499-0},
  pdf      = {https://www.nature.com/articles/s41467-023-40499-0.pdf},
  selected = {true},
  language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Veerabadran2021-rp,
  title     = "Bio-inspired learnable divisive normalization for {ANNs}",
  author    = "Veerabadran, Vijay and Raina, Ritik and De Sa, Virginia R",
  abstract  = "In this work we introduce DivNormEI, a novel bio-inspired
               convolutional network that performs divisive normalization, a
               canonical cortical computation, along with lateral …",
  journal   = "3rd Workshop on Shared Visual Representations in Human and Machine Intelligence (SVRHM), NeurIPS",
  publisher = "openreview.net",
  year      =  2021,
  html     =  {https://sites.google.com/view/neurips2019-svrhm2019/call-for-papers?authuser=0},
  abbr    = {NeurIPS 2021},
  pdf      =  {https://drive.google.com/file/d/1w8o_yhIvosTSCrv0Y-VAu9GT1_zXSDIX/view},
  selected =  {true},
  keywords  = "Vijay's pubs"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Veerabadran2020-jj,
  abbr = {CVPRW 2020},
  title     = "Adversarial distortion for learned video compression",
  author    = "Veerabadran, Vijay and Pourreza, R and {others}",
  abstract  = "In this paper, we present a novel adversarial lossy video
               compression model. At extremely low bit-rates, standard video
               coding schemes suffer from unpleasant reconstruction artifacts …",
  journal   = "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops",
  publisher = "openaccess.thecvf.com",
  year      =  2020,
  selected =  {true},
  html = {https://ieeexplore.ieee.org/document/9150830},
  pdf = {https://openaccess.thecvf.com/content_CVPRW_2020/papers/w7/Veerabadran_Adversarial_Distortion_for_Learned_Video_Compression_CVPRW_2020_paper.pdf},
  keywords  = "Vijay's pubs"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Linsley2018-iy,
  abbr = {NeurIPS 2018},
  title     = "Learning long-range spatial dependencies with horizontal gated
               recurrent units",
  author    = "Linsley, D and Kim, J and Veerabadran, Vijay and {others}",
  abstract  = "Progress in deep learning has spawned great successes in many
               engineering applications. As a prime example, convolutional
               neural networks, a type of feedforward neural networks …",
  journal   = "Proceedings of the 32nd International Conference on Neural Information Processing Systems",
  publisher = "proceedings.neurips.cc",
  year      =  2018,
  selected =  {true},
  html = {https://proceedings.neurips.cc/paper/2018/hash/ec8956637a99787bd197eacd77acce5e-Abstract.html},
  pdf = {https://arxiv.org/pdf/1805.08315.pdf},
  keywords  = "Vijay's pubs"
}
