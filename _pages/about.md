---
layout: about
title: About
permalink: /
subtitle: PhD'ing at <a href="#">UC San Diego</a>.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  address:
  

news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hello! I am a Research Scientist at Reality Labs Research @ Meta working on egocentric video language models for wearable devices. Previously, I was a Ph.D. student advised by [Dr. Virginia de Sa](http://www.cogsci.ucsd.edu/~desa/) at the [UCSD Cognitive Science](http://cogsci.ucsd.edu) department where I worked on computer vision and human vision. My main contributions from my PhD research are (1) a bio-inspired adaptive RNN architecture that learned to dynamically scale its computation with input task-difficulty (see [NeurIPS23](https://proceedings.neurips.cc/paper_files/paper/2023/file/3a40e042c66e84659249f3254460c123-Paper-Conference.pdf)), and (2) studying human vision's sensitivity to adversarial image perturbations (see [NatComm23](https://www.nature.com/articles/s41467-023-40499-0)).

During my PhD, I did internships at Google Brain, Facebook AI Research and Qualcomm AI Research working on adversarial images, human visual perception, self-supervised learning and unsupervised video representation learning.
